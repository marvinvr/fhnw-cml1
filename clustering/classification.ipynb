{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification House-types\n",
    "#### Anforderungen:\n",
    "<p> Entwickle und vergleiche drei sinnvolle Modelle zur Klassifikation von Immobilien Objekten hinsichtlich `type`. </p>\n",
    "<p> Was sind sinnvolle Metriken zur Messung der Genauigkeit der Vorhersage im vorliegenden Fall? Was ist zu beachten um eine gute Abschätzung des Fehlers für neue Daten zu bekommen? </p>\n",
    "<p> Rapportiere diese Metrik(en) mit einer Abschätzung des Fehlers für alle drei Modelle </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForestDensityM</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>NoisePollutionRailwayM</th>\n",
       "      <th>NoisePollutionRoadM</th>\n",
       "      <th>PopulationDensityM</th>\n",
       "      <th>RiversAndLakesM</th>\n",
       "      <th>RiversAndLakesS</th>\n",
       "      <th>distanceToTrainStation</th>\n",
       "      <th>gde_area_agriculture_percentage</th>\n",
       "      <th>...</th>\n",
       "      <th>type_penthouse</th>\n",
       "      <th>type_rustico</th>\n",
       "      <th>type_secondary-suite</th>\n",
       "      <th>type_semi-detached-house</th>\n",
       "      <th>type_single-room</th>\n",
       "      <th>type_stepped-apartment</th>\n",
       "      <th>type_stepped-house</th>\n",
       "      <th>type_studio</th>\n",
       "      <th>type_terrace-house</th>\n",
       "      <th>type_villa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13373</th>\n",
       "      <td>-0.213010</td>\n",
       "      <td>0.614418</td>\n",
       "      <td>0.482482</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.065714</td>\n",
       "      <td>0.826321</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.010277</td>\n",
       "      <td>0.214048</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13374</th>\n",
       "      <td>0.030807</td>\n",
       "      <td>0.659631</td>\n",
       "      <td>0.467615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685309</td>\n",
       "      <td>0.539041</td>\n",
       "      <td>164.44881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524307</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13375</th>\n",
       "      <td>-0.213010</td>\n",
       "      <td>0.812664</td>\n",
       "      <td>0.476216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.004834</td>\n",
       "      <td>0.721307</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.022768</td>\n",
       "      <td>0.789850</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13376</th>\n",
       "      <td>0.288199</td>\n",
       "      <td>0.703465</td>\n",
       "      <td>0.506514</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061288</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.893323</td>\n",
       "      <td>0.279233</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13377</th>\n",
       "      <td>0.516765</td>\n",
       "      <td>0.755503</td>\n",
       "      <td>0.512116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.148699</td>\n",
       "      <td>0.256523</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.295925</td>\n",
       "      <td>-0.287039</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ForestDensityM  Latitude  Longitude  NoisePollutionRailwayM  \\\n",
       "13373       -0.213010  0.614418   0.482482                     0.0   \n",
       "13374        0.030807  0.659631   0.467615                     0.0   \n",
       "13375       -0.213010  0.812664   0.476216                     0.0   \n",
       "13376        0.288199  0.703465   0.506514                     0.0   \n",
       "13377        0.516765  0.755503   0.512116                     0.0   \n",
       "\n",
       "       NoisePollutionRoadM  PopulationDensityM  RiversAndLakesM  \\\n",
       "13373            -0.065714            0.826321          0.00000   \n",
       "13374             0.685309            0.539041        164.44881   \n",
       "13375            -0.004834            0.721307          0.00000   \n",
       "13376             0.061288            0.245098          0.00000   \n",
       "13377            -1.148699            0.256523          0.00000   \n",
       "\n",
       "       RiversAndLakesS  distanceToTrainStation  \\\n",
       "13373              0.0               -0.010277   \n",
       "13374              0.0                0.524307   \n",
       "13375              0.0               -0.022768   \n",
       "13376              0.0                0.893323   \n",
       "13377              0.0               -0.295925   \n",
       "\n",
       "       gde_area_agriculture_percentage  ...  type_penthouse  type_rustico  \\\n",
       "13373                         0.214048  ...               0             0   \n",
       "13374                         0.111050  ...               0             0   \n",
       "13375                         0.789850  ...               0             0   \n",
       "13376                         0.279233  ...               0             0   \n",
       "13377                        -0.287039  ...               0             0   \n",
       "\n",
       "       type_secondary-suite  type_semi-detached-house  type_single-room  \\\n",
       "13373                     0                         0                 0   \n",
       "13374                     0                         1                 0   \n",
       "13375                     0                         0                 0   \n",
       "13376                     0                         0                 0   \n",
       "13377                     0                         0                 0   \n",
       "\n",
       "       type_stepped-apartment  type_stepped-house  type_studio  \\\n",
       "13373                       0                   0            0   \n",
       "13374                       0                   0            0   \n",
       "13375                       0                   0            0   \n",
       "13376                       0                   0            0   \n",
       "13377                       0                   0            0   \n",
       "\n",
       "       type_terrace-house  type_villa  \n",
       "13373                   0           0  \n",
       "13374                   0           0  \n",
       "13375                   1           0  \n",
       "13376                   0           0  \n",
       "13377                   0           0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('../data/model/immoscout_robust.csv')\n",
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column with different types\n",
    "types = [col for col in df.columns if 'type' in col]\n",
    "df['type'] = df[types].idxmax(axis=1)\n",
    "df['type'] = df['type'].str.replace('type_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into features and target variables and drop type-columns for the features\n",
    "types.append('type')\n",
    "X = df.drop(types, axis=1)\n",
    "y = df['type']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y):\n",
    "    return model_selection.train_test_split(X, y, train_size=0.6, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eingabe unklar umwandlung column in np-array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select random columns for the features\n",
    "def get_random_column_names(columns: list, percentage: float, add_type_columns: bool) -> list:\n",
    "    type_columns = [c for c in columns if c.startswith(\"type_\") and add_type_columns]\n",
    "    regular_columns = [c for c in columns if (not c.startswith(\"type_\")) and random.random() < percentage]\n",
    "    return [*type_columns, *regular_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def knn(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    model = KNeighborsClassifier(n_neighbors= 5)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"RandomForest\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of iterations: 1000\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "NUM_ITERATIONS = 500\n",
    "MIN_PERCENTAGE_COLUMNS = 0.2\n",
    "MAX_PERCENTAGE_COLUMNS = 1\n",
    "TRAINING_FUNCTIONS = [knn]\n",
    "\n",
    "print(\"Total number of iterations:\", NUM_ITERATIONS * len(TRAINING_FUNCTIONS) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\yanni\\OneDrive\\FHNW\\Challenges\\Immobilienrechner\\fhnw-cml1\\clustering\\classification.ipynb Zelle 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         temp_X_train, temp_X_test \u001b[39m=\u001b[39m X_train[column_names], X_test[column_names]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39mfor\u001b[39;00m func \u001b[39min\u001b[39;00m TRAINING_FUNCTIONS:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m             results\u001b[39m.\u001b[39mappend({\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfunc(temp_X_train, temp_X_test, y_train, y_test), \u001b[39m\"\u001b[39m\u001b[39madd_type_columns\u001b[39m\u001b[39m\"\u001b[39m: add_type_columns})\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(results)\u001b[39m.\u001b[39msort_values(\u001b[39m\"\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m\"\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\yanni\\OneDrive\\FHNW\\Challenges\\Immobilienrechner\\fhnw-cml1\\clustering\\classification.ipynb Zelle 11\u001b[0m in \u001b[0;36mknn\u001b[1;34m(X_train, X_test, y_train, y_test)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mknn\u001b[39m(X_train: pd\u001b[39m.\u001b[39mDataFrame, X_test: pd\u001b[39m.\u001b[39mDataFrame, y_train: pd\u001b[39m.\u001b[39mSeries, y_test: pd\u001b[39m.\u001b[39mSeries) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     model \u001b[39m=\u001b[39m KNeighborsClassifier(n_neighbors\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mRandomForest\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mlist\u001b[39m(X_train\u001b[39m.\u001b[39mcolumns),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m: model\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/yanni/OneDrive/FHNW/Challenges/Immobilienrechner/fhnw-cml1/clustering/classification.ipynb#X16sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:200\u001b[0m, in \u001b[0;36mKNeighborsClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[39m\"\"\"Fit the k-nearest neighbors classifier from the training dataset.\u001b[39;00m\n\u001b[0;32m    182\u001b[0m \n\u001b[0;32m    183\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[39m    The fitted k-nearest neighbors classifier.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights \u001b[39m=\u001b[39m _check_weights(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)\n\u001b[1;32m--> 200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\neighbors\\_base.py:407\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tags()[\u001b[39m\"\u001b[39m\u001b[39mrequires_y\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m    406\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 407\u001b[0m         X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    408\u001b[0m             X, y, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m    409\u001b[0m         )\n\u001b[0;32m    411\u001b[0m     \u001b[39mif\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[0;32m    412\u001b[0m         \u001b[39m# Classification targets require a specific format\u001b[39;00m\n\u001b[0;32m    413\u001b[0m         \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mor\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39mand\u001b[39;00m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\base.py:596\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    594\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    595\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    597\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:1074\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1069\u001b[0m         estimator_name \u001b[39m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1070\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1071\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m requires y to be passed, but the target y is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1072\u001b[0m     )\n\u001b[1;32m-> 1074\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m   1075\u001b[0m     X,\n\u001b[0;32m   1076\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m   1077\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m   1078\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m   1079\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m   1080\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m   1081\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m   1082\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m   1083\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m   1084\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m   1085\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m   1086\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m   1087\u001b[0m     input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1088\u001b[0m )\n\u001b[0;32m   1090\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m   1092\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:899\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    893\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    894\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    895\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    896\u001b[0m         )\n\u001b[0;32m    898\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 899\u001b[0m         _assert_all_finite(\n\u001b[0;32m    900\u001b[0m             array,\n\u001b[0;32m    901\u001b[0m             input_name\u001b[39m=\u001b[39;49minput_name,\n\u001b[0;32m    902\u001b[0m             estimator_name\u001b[39m=\u001b[39;49mestimator_name,\n\u001b[0;32m    903\u001b[0m             allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    904\u001b[0m         )\n\u001b[0;32m    906\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    907\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:146\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    125\u001b[0m             \u001b[39mnot\u001b[39;00m allow_nan\n\u001b[0;32m    126\u001b[0m             \u001b[39mand\u001b[39;00m estimator_name\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[39m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    131\u001b[0m             \u001b[39m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    132\u001b[0m             msg_err \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mestimator_name\u001b[39m}\u001b[39;00m\u001b[39m does not accept missing values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m#estimators-that-handle-nan-values\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    145\u001b[0m             )\n\u001b[1;32m--> 146\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg_err)\n\u001b[0;32m    148\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n",
      "\u001b[1;31mValueError\u001b[0m: Input X contains NaN.\nKNeighborsClassifier does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(NUM_ITERATIONS):\n",
    "    for add_type_columns in [True, False]:\n",
    "        column_percentage = random.random() * (MAX_PERCENTAGE_COLUMNS - MIN_PERCENTAGE_COLUMNS) + MIN_PERCENTAGE_COLUMNS\n",
    "        column_names = get_random_column_names(X_train.columns, column_percentage, add_type_columns)\n",
    "        temp_X_train, temp_X_test = X_train[column_names], X_test[column_names]\n",
    "\n",
    "        for func in TRAINING_FUNCTIONS:\n",
    "            results.append({**func(temp_X_train, temp_X_test, y_train, y_test), \"add_type_columns\": add_type_columns})\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"score\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
