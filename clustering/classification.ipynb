{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification House-types\n",
    "#### Anforderungen:\n",
    "<p> Entwickle und vergleiche drei sinnvolle Modelle zur Klassifikation von Immobilien Objekten hinsichtlich `type`. </p>\n",
    "<p> Was sind sinnvolle Metriken zur Messung der Genauigkeit der Vorhersage im vorliegenden Fall? Was ist zu beachten um eine gute Abschätzung des Fehlers für neue Daten zu bekommen? </p>\n",
    "<p> Rapportiere diese Metrik(en) mit einer Abschätzung des Fehlers für alle drei Modelle </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import model_selection, svm, ensemble, tree\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import xgboost as xgb\n",
    "#from boruta import BorutaPy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Living space</th>\n",
       "      <th>Plot area</th>\n",
       "      <th>Floor</th>\n",
       "      <th>ForestDensityL</th>\n",
       "      <th>ForestDensityM</th>\n",
       "      <th>ForestDensityS</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>NoisePollutionRailwayL</th>\n",
       "      <th>NoisePollutionRailwayM</th>\n",
       "      <th>...</th>\n",
       "      <th>gde_workers_sector3_4</th>\n",
       "      <th>gde_workers_sector3_5</th>\n",
       "      <th>gde_workers_total_2</th>\n",
       "      <th>gde_workers_total_3</th>\n",
       "      <th>gde_workers_total_4</th>\n",
       "      <th>gde_workers_total_5</th>\n",
       "      <th>rooms_2</th>\n",
       "      <th>rooms_3</th>\n",
       "      <th>rooms_4</th>\n",
       "      <th>rooms_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009716</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.286608</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.808677</td>\n",
       "      <td>0.477811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.204691e-13</td>\n",
       "      <td>1.510722e-16</td>\n",
       "      <td>4.489742e-07</td>\n",
       "      <td>3.008376e-10</td>\n",
       "      <td>2.015778e-13</td>\n",
       "      <td>1.350683e-16</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015504</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.286608</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.808677</td>\n",
       "      <td>0.477811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.204691e-13</td>\n",
       "      <td>1.510722e-16</td>\n",
       "      <td>4.489742e-07</td>\n",
       "      <td>3.008376e-10</td>\n",
       "      <td>2.015778e-13</td>\n",
       "      <td>1.350683e-16</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008992</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.426764</td>\n",
       "      <td>0.095930</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.799258</td>\n",
       "      <td>0.468164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.280957e-05</td>\n",
       "      <td>1.576327e-06</td>\n",
       "      <td>5.103043e-03</td>\n",
       "      <td>3.645388e-04</td>\n",
       "      <td>2.604104e-05</td>\n",
       "      <td>1.860257e-06</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015297</td>\n",
       "      <td>0.001009</td>\n",
       "      <td>0.207143</td>\n",
       "      <td>0.754914</td>\n",
       "      <td>0.286608</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.808677</td>\n",
       "      <td>0.477811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.204691e-13</td>\n",
       "      <td>1.510722e-16</td>\n",
       "      <td>4.489742e-07</td>\n",
       "      <td>3.008376e-10</td>\n",
       "      <td>2.015778e-13</td>\n",
       "      <td>1.350683e-16</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014057</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.610095</td>\n",
       "      <td>0.279429</td>\n",
       "      <td>0.145835</td>\n",
       "      <td>0.803051</td>\n",
       "      <td>0.470341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.043945e-11</td>\n",
       "      <td>4.345968e-14</td>\n",
       "      <td>8.152190e-06</td>\n",
       "      <td>2.327617e-08</td>\n",
       "      <td>6.645820e-11</td>\n",
       "      <td>1.897517e-13</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 262 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Living space  Plot area     Floor  ForestDensityL  ForestDensityM  \\\n",
       "0      0.009716   0.001532  0.285714        0.754914        0.286608   \n",
       "1      0.015504   0.000587  0.228571        0.754914        0.286608   \n",
       "2      0.008992   0.005032  0.214286        0.426764        0.095930   \n",
       "3      0.015297   0.001009  0.207143        0.754914        0.286608   \n",
       "4      0.014057   0.001619  0.142857        0.610095        0.279429   \n",
       "\n",
       "   ForestDensityS  Latitude  Longitude  NoisePollutionRailwayL  \\\n",
       "0        0.090908  0.808677   0.477811                     0.0   \n",
       "1        0.090908  0.808677   0.477811                     0.0   \n",
       "2        0.001911  0.799258   0.468164                     0.0   \n",
       "3        0.090908  0.808677   0.477811                     0.0   \n",
       "4        0.145835  0.803051   0.470341                     0.0   \n",
       "\n",
       "   NoisePollutionRailwayM  ...  gde_workers_sector3_4  gde_workers_sector3_5  \\\n",
       "0                     0.0  ...           2.204691e-13           1.510722e-16   \n",
       "1                     0.0  ...           2.204691e-13           1.510722e-16   \n",
       "2                     0.0  ...           2.280957e-05           1.576327e-06   \n",
       "3                     0.0  ...           2.204691e-13           1.510722e-16   \n",
       "4                     0.0  ...           2.043945e-11           4.345968e-14   \n",
       "\n",
       "   gde_workers_total_2  gde_workers_total_3  gde_workers_total_4  \\\n",
       "0         4.489742e-07         3.008376e-10         2.015778e-13   \n",
       "1         4.489742e-07         3.008376e-10         2.015778e-13   \n",
       "2         5.103043e-03         3.645388e-04         2.604104e-05   \n",
       "3         4.489742e-07         3.008376e-10         2.015778e-13   \n",
       "4         8.152190e-06         2.327617e-08         6.645820e-11   \n",
       "\n",
       "   gde_workers_total_5   rooms_2   rooms_3   rooms_4   rooms_5  \n",
       "0         1.350683e-16  0.020408  0.002915  0.000416  0.000059  \n",
       "1         1.350683e-16  0.020408  0.002915  0.000416  0.000059  \n",
       "2         1.860257e-06  0.020408  0.002915  0.000416  0.000059  \n",
       "3         1.350683e-16  0.020408  0.002915  0.000416  0.000059  \n",
       "4         1.897517e-13  0.020408  0.002915  0.000416  0.000059  \n",
       "\n",
       "[5 rows x 262 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import dataset\n",
    "df = pd.read_csv('../data/model/immoscout_min_max_v2.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column with different types\n",
    "types = [col for col in df.columns if 'type' in col]\n",
    "# dummies in one column\n",
    "df['type'] = df[types].idxmax(axis=1)\n",
    "df['type'] = df['type'].str.replace('type_unified_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_clean has to be tranformed and scaled and add their power in df\n",
    "df['price_cleaned'] = df['price_cleaned'] ** 0.5\n",
    "df['price_cleaned'] = (df['price_cleaned'] - df['price_cleaned'].min()) / (df['price_cleaned'].max() - df['price_cleaned'].min())\n",
    "for i in range(1, 6):\n",
    "    df[f'price_cleaned_{i}'] = df['price_cleaned'] ** i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = df.drop('type', axis=1)\n",
    "y = df['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest-neighbour\n",
    "def knn(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    model = KNeighborsClassifier(n_neighbors= 5)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"K-Nearest-Neighbour\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        'accuracy': accuracy_score(y_test, y_predict),\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine other kernels should be tried\n",
    "def svm(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    model = SVC(kernel= 'rbf')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"SVM\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        'accuracy': accuracy_score(y_test, y_predict),\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Classifier max depth and other coefficients should be tried\n",
    "def random_forest(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    model = ensemble.RandomForestClassifier(n_estimators=100, criterion = 'gini', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"RandomForest\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        'accuracy': accuracy_score(y_test, y_predict),\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "def xg_boost(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    labelencoder = LabelEncoder()\n",
    "    y_train = labelencoder.fit_transform(y_train)\n",
    "    y_test = labelencoder.fit_transform(y_test)\n",
    "    model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"XGBoost\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        'accuracy': accuracy_score(y_test, y_predict),\n",
    "        \"model\": model\n",
    "    }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of iterations: 16\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "NUM_ITERATIONS = 2\n",
    "MIN_PERCENTAGE_COLUMNS = 0.2\n",
    "MAX_PERCENTAGE_COLUMNS = 1\n",
    "TRAINING_FUNCTIONS = [knn, svm, random_forest, xg_boost]\n",
    "\n",
    "print(\"Total number of iterations:\", NUM_ITERATIONS * len(TRAINING_FUNCTIONS) * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>columns</th>\n",
       "      <th>num_columns</th>\n",
       "      <th>score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>model</th>\n",
       "      <th>add_type_columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.639129</td>\n",
       "      <td>0.639129</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.634623</td>\n",
       "      <td>0.634623</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.603267</td>\n",
       "      <td>0.603267</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.598010</td>\n",
       "      <td>0.598010</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>[Longitude, NoisePollutionRoadM, PopulationDen...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.587683</td>\n",
       "      <td>0.587683</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>[Longitude, NoisePollutionRoadM, PopulationDen...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.571911</td>\n",
       "      <td>0.571911</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest-Neighbour</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.552197</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-Nearest-Neighbour</td>\n",
       "      <td>[Longitude, NoisePollutionRoadM, PopulationDen...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.546752</td>\n",
       "      <td>0.546752</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>K-Nearest-Neighbour</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.530980</td>\n",
       "      <td>0.530980</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>[ForestDensityM, NoisePollutionRailwayM, gde_a...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.486106</td>\n",
       "      <td>0.486106</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>[ForestDensityM, NoisePollutionRailwayM, gde_a...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.483102</td>\n",
       "      <td>0.483102</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='gbtree'...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>K-Nearest-Neighbour</td>\n",
       "      <td>[ForestDensityM, NoisePollutionRailwayM, gde_a...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.465452</td>\n",
       "      <td>0.465452</td>\n",
       "      <td>KNeighborsClassifier()</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>28</td>\n",
       "      <td>0.451934</td>\n",
       "      <td>0.451934</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>[ForestDensityM, Latitude, Longitude, NoisePol...</td>\n",
       "      <td>25</td>\n",
       "      <td>0.450244</td>\n",
       "      <td>0.450244</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVM</td>\n",
       "      <td>[Longitude, NoisePollutionRoadM, PopulationDen...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.450244</td>\n",
       "      <td>0.450244</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM</td>\n",
       "      <td>[ForestDensityM, NoisePollutionRailwayM, gde_a...</td>\n",
       "      <td>9</td>\n",
       "      <td>0.446677</td>\n",
       "      <td>0.446677</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   type                                            columns  \\\n",
       "6          RandomForest  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "2          RandomForest  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "3               XGBoost  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "7               XGBoost  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "14         RandomForest  [Longitude, NoisePollutionRoadM, PopulationDen...   \n",
       "15              XGBoost  [Longitude, NoisePollutionRoadM, PopulationDen...   \n",
       "4   K-Nearest-Neighbour  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "12  K-Nearest-Neighbour  [Longitude, NoisePollutionRoadM, PopulationDen...   \n",
       "0   K-Nearest-Neighbour  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "10         RandomForest  [ForestDensityM, NoisePollutionRailwayM, gde_a...   \n",
       "11              XGBoost  [ForestDensityM, NoisePollutionRailwayM, gde_a...   \n",
       "8   K-Nearest-Neighbour  [ForestDensityM, NoisePollutionRailwayM, gde_a...   \n",
       "1                   SVM  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "5                   SVM  [ForestDensityM, Latitude, Longitude, NoisePol...   \n",
       "13                  SVM  [Longitude, NoisePollutionRoadM, PopulationDen...   \n",
       "9                   SVM  [ForestDensityM, NoisePollutionRailwayM, gde_a...   \n",
       "\n",
       "    num_columns     score  accuracy  \\\n",
       "6            25  0.639129  0.639129   \n",
       "2            28  0.634623  0.634623   \n",
       "3            28  0.603267  0.603267   \n",
       "7            25  0.598010  0.598010   \n",
       "14           19  0.587683  0.587683   \n",
       "15           19  0.571911  0.571911   \n",
       "4            25  0.552197  0.552197   \n",
       "12           19  0.546752  0.546752   \n",
       "0            28  0.530980  0.530980   \n",
       "10            9  0.486106  0.486106   \n",
       "11            9  0.483102  0.483102   \n",
       "8             9  0.465452  0.465452   \n",
       "1            28  0.451934  0.451934   \n",
       "5            25  0.450244  0.450244   \n",
       "13           19  0.450244  0.450244   \n",
       "9             9  0.446677  0.446677   \n",
       "\n",
       "                                                model  add_type_columns  \n",
       "6   (DecisionTreeClassifier(max_features='sqrt', r...             False  \n",
       "2   (DecisionTreeClassifier(max_features='sqrt', r...              True  \n",
       "3   XGBClassifier(base_score=0.5, booster='gbtree'...              True  \n",
       "7   XGBClassifier(base_score=0.5, booster='gbtree'...             False  \n",
       "14  (DecisionTreeClassifier(max_features='sqrt', r...             False  \n",
       "15  XGBClassifier(base_score=0.5, booster='gbtree'...             False  \n",
       "4                              KNeighborsClassifier()             False  \n",
       "12                             KNeighborsClassifier()             False  \n",
       "0                              KNeighborsClassifier()              True  \n",
       "10  (DecisionTreeClassifier(max_features='sqrt', r...              True  \n",
       "11  XGBClassifier(base_score=0.5, booster='gbtree'...              True  \n",
       "8                              KNeighborsClassifier()              True  \n",
       "1                                               SVC()              True  \n",
       "5                                               SVC()             False  \n",
       "13                                              SVC()             False  \n",
       "9                                               SVC()              True  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train different Models\n",
    "results = []\n",
    "for _ in range(NUM_ITERATIONS):\n",
    "    for add_type_columns in [True, False]:\n",
    "        column_percentage = random.random() * (MAX_PERCENTAGE_COLUMNS - MIN_PERCENTAGE_COLUMNS) + MIN_PERCENTAGE_COLUMNS\n",
    "        column_names = get_random_column_names(X_train.columns, column_percentage, add_type_columns)\n",
    "        temp_X_train, temp_X_test = X_train[column_names], X_test[column_names]\n",
    "\n",
    "        for func in TRAINING_FUNCTIONS:\n",
    "            results.append({**func(temp_X_train, temp_X_test, y_train, y_test), \"add_type_columns\": add_type_columns})\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"score\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Offene Punkte:\n",
    "Random Forest domminiert\n",
    "\n",
    "try different kernel, forste depth etc...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature selection with the best performing Models\n",
    "BorutayPy tries different cominations with different Features and ranks the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=42, max_iter=200)\\nselector.fit(X_train.values, y_train.values)\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''selector = BorutaPy(model, n_estimators='auto', verbose=2, random_state=42, max_iter=200)\n",
    "selector.fit(X_train.values, y_train.values)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x_filtered = selector.transform(X_train.values)\\nx_filtered'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''x_filtered = selector.transform(X_train.values)\n",
    "x_filtered'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ranking = list(zip(X_train.columns, selector.ranking_, selector.support_))\\nranking.sort(key=lambda x: x[1])\\nranking'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''ranking = list(zip(X_train.columns, selector.ranking_, selector.support_))\n",
    "ranking.sort(key=lambda x: x[1])\n",
    "ranking'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"#ranking as a dataframe\\nranking_df = pd.DataFrame(ranking, columns=['Feature name', 'Ranking', 'Support'])\\nranking_df\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''#ranking as a dataframe\n",
    "ranking_df = pd.DataFrame(ranking, columns=['Feature name', 'Ranking', 'Support'])\n",
    "ranking_df'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_df = pd.read_csv('ranking_features_borutapy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Latitude',\n",
       " 'Longitude',\n",
       " 'PopulationDensityM',\n",
       " 'distanceToTrainStation',\n",
       " 'gde_politics_svp',\n",
       " 'gde_pop_per_km2',\n",
       " 'rooms',\n",
       " 'Floor space_m2',\n",
       " 'Plot area_m2',\n",
       " 'living_space_m2',\n",
       " 'price']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(ranking_df[ranking_df['Support'] == True]['Feature name'].values)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[features]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gini', 'entropy', 'log_loss'],\n",
       " [0.6740518212542246, 0.6714232069095005, 0.6714232069095005])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try different functions\n",
    "models = ['gini', 'entropy', 'log_loss']\n",
    "score  = []\n",
    "\n",
    "for model in models:\n",
    "    model = ensemble.RandomForestClassifier(n_estimators=100, criterion = model, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    score.append(accuracy_score(y_test, y_predict))\n",
    "models, score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gini performs best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [99], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m estimators:\n\u001b[1;32m      6\u001b[0m     model \u001b[39m=\u001b[39m ensemble\u001b[39m.\u001b[39mRandomForestClassifier(n_estimators\u001b[39m=\u001b[39m i, criterion \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mgini\u001b[39m\u001b[39m'\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      8\u001b[0m     y_predict \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m      9\u001b[0m     score\u001b[39m.\u001b[39mappend(accuracy_score(y_test, y_predict))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:476\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    466\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    468\u001b[0m ]\n\u001b[1;32m    470\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    475\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 476\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    477\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    478\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    479\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    480\u001b[0m )(\n\u001b[1;32m    481\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    482\u001b[0m         t,\n\u001b[1;32m    483\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbootstrap,\n\u001b[1;32m    484\u001b[0m         X,\n\u001b[1;32m    485\u001b[0m         y,\n\u001b[1;32m    486\u001b[0m         sample_weight,\n\u001b[1;32m    487\u001b[0m         i,\n\u001b[1;32m    488\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    489\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    490\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    491\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    492\u001b[0m     )\n\u001b[1;32m    493\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    494\u001b[0m )\n\u001b[1;32m    496\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:189\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[39melif\u001b[39;00m class_weight \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbalanced_subsample\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    187\u001b[0m         curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m compute_sample_weight(\u001b[39m\"\u001b[39m\u001b[39mbalanced\u001b[39m\u001b[39m\"\u001b[39m, y, indices\u001b[39m=\u001b[39mindices)\n\u001b[0;32m--> 189\u001b[0m     tree\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49mcurr_sample_weight, check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    190\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m     tree\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight, check_input\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "estimators = [10, 20, 50, 100, 200, 500]\n",
    "score  = []\n",
    "depth = []\n",
    "\n",
    "for i in estimators:\n",
    "    model = ensemble.RandomForestClassifier(n_estimators= i, criterion = 'gini', random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predict = model.predict(X_test)\n",
    "    score.append(accuracy_score(y_test, y_predict))\n",
    "    iteration_depth = [estimator.get_depth() for estimator in model.estimators_]\n",
    "    depth.append(max(iteration_depth))\n",
    "    depth.append(min(iteration_depth))\n",
    "    depth.append(np.mean(iteration_depth))\n",
    "\n",
    "estimators, score, depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### we get the best result arround 100 trees in the randomforest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
