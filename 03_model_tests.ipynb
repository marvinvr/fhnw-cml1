{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Tests"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## General"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model, model_selection, ensemble, tree\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "   ForestDensityM  Latitude  Longitude  NoisePollutionRailwayM  \\\n0        1.067960  0.686833   0.130463                0.000000   \n1        1.067960  0.686833   0.130463                0.000000   \n2        0.215740  0.668920   0.106747                0.000000   \n3        1.067960  0.686833   0.130463                0.000000   \n4        1.035876  0.676133   0.112097                0.000000   \n5        0.515181  0.672546   0.089462                0.000000   \n6        1.067960  0.686833   0.130463                0.000000   \n7       -0.213010  0.660603   0.106216              103.826366   \n8        1.747204  0.672320   0.122047                6.816164   \n9        0.413429  0.666867   0.089861                0.000000   \n\n   NoisePollutionRoadM  PopulationDensityM  RiversAndLakesM  RiversAndLakesS  \\\n0            -1.129839            0.010313        18.218171         0.011871   \n1            -1.129839            0.010313        18.218171         0.011871   \n2             0.715909            0.804150      1893.128856         0.000000   \n3            -1.129839            0.010313        18.218171         0.011871   \n4            -0.742810           -0.302241      1422.882194         0.091805   \n5            -0.682468            0.137930         0.000000         0.000000   \n6            -1.129839            0.010313        18.218171         0.011871   \n7             0.677604            0.186520         0.000000         0.000000   \n8             0.882613            0.141751       391.719036         0.034402   \n9            -0.236134            0.007740         0.000000         0.000000   \n\n   distanceToTrainStation  gde_area_agriculture_percentage  ...  \\\n0                0.987703                        -0.102607  ...   \n1                0.987703                        -0.102607  ...   \n2               -0.071577                        -0.709981  ...   \n3                0.987703                        -0.102607  ...   \n4                0.202417                        -0.025255  ...   \n5                1.042194                        -0.029724  ...   \n6                0.987703                        -0.102607  ...   \n7               -0.156544                        -0.709981  ...   \n8               -0.017196                        -0.709981  ...   \n9                0.878246                        -0.029724  ...   \n\n   type_penthouse  type_rustico  type_secondary-suite  \\\n0               1             0                     0   \n1               0             0                     0   \n2               1             0                     0   \n3               0             0                     0   \n4               0             0                     0   \n5               0             0                     0   \n6               0             0                     0   \n7               0             0                     0   \n8               0             0                     0   \n9               0             0                     0   \n\n   type_semi-detached-house  type_single-room  type_stepped-apartment  \\\n0                         0                 0                       0   \n1                         0                 0                       0   \n2                         0                 0                       0   \n3                         0                 0                       0   \n4                         0                 0                       0   \n5                         0                 0                       0   \n6                         0                 0                       0   \n7                         0                 0                       0   \n8                         0                 0                       0   \n9                         0                 0                       0   \n\n   type_stepped-house  type_studio  type_terrace-house  type_villa  \n0                   0            0                   0           0  \n1                   0            0                   1           0  \n2                   0            0                   0           0  \n3                   0            0                   0           0  \n4                   0            0                   0           0  \n5                   0            0                   0           0  \n6                   0            0                   1           0  \n7                   0            0                   0           0  \n8                   0            0                   0           0  \n9                   1            0                   0           0  \n\n[10 rows x 57 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ForestDensityM</th>\n      <th>Latitude</th>\n      <th>Longitude</th>\n      <th>NoisePollutionRailwayM</th>\n      <th>NoisePollutionRoadM</th>\n      <th>PopulationDensityM</th>\n      <th>RiversAndLakesM</th>\n      <th>RiversAndLakesS</th>\n      <th>distanceToTrainStation</th>\n      <th>gde_area_agriculture_percentage</th>\n      <th>...</th>\n      <th>type_penthouse</th>\n      <th>type_rustico</th>\n      <th>type_secondary-suite</th>\n      <th>type_semi-detached-house</th>\n      <th>type_single-room</th>\n      <th>type_stepped-apartment</th>\n      <th>type_stepped-house</th>\n      <th>type_studio</th>\n      <th>type_terrace-house</th>\n      <th>type_villa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.067960</td>\n      <td>0.686833</td>\n      <td>0.130463</td>\n      <td>0.000000</td>\n      <td>-1.129839</td>\n      <td>0.010313</td>\n      <td>18.218171</td>\n      <td>0.011871</td>\n      <td>0.987703</td>\n      <td>-0.102607</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.067960</td>\n      <td>0.686833</td>\n      <td>0.130463</td>\n      <td>0.000000</td>\n      <td>-1.129839</td>\n      <td>0.010313</td>\n      <td>18.218171</td>\n      <td>0.011871</td>\n      <td>0.987703</td>\n      <td>-0.102607</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.215740</td>\n      <td>0.668920</td>\n      <td>0.106747</td>\n      <td>0.000000</td>\n      <td>0.715909</td>\n      <td>0.804150</td>\n      <td>1893.128856</td>\n      <td>0.000000</td>\n      <td>-0.071577</td>\n      <td>-0.709981</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.067960</td>\n      <td>0.686833</td>\n      <td>0.130463</td>\n      <td>0.000000</td>\n      <td>-1.129839</td>\n      <td>0.010313</td>\n      <td>18.218171</td>\n      <td>0.011871</td>\n      <td>0.987703</td>\n      <td>-0.102607</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.035876</td>\n      <td>0.676133</td>\n      <td>0.112097</td>\n      <td>0.000000</td>\n      <td>-0.742810</td>\n      <td>-0.302241</td>\n      <td>1422.882194</td>\n      <td>0.091805</td>\n      <td>0.202417</td>\n      <td>-0.025255</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.515181</td>\n      <td>0.672546</td>\n      <td>0.089462</td>\n      <td>0.000000</td>\n      <td>-0.682468</td>\n      <td>0.137930</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.042194</td>\n      <td>-0.029724</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.067960</td>\n      <td>0.686833</td>\n      <td>0.130463</td>\n      <td>0.000000</td>\n      <td>-1.129839</td>\n      <td>0.010313</td>\n      <td>18.218171</td>\n      <td>0.011871</td>\n      <td>0.987703</td>\n      <td>-0.102607</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>-0.213010</td>\n      <td>0.660603</td>\n      <td>0.106216</td>\n      <td>103.826366</td>\n      <td>0.677604</td>\n      <td>0.186520</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.156544</td>\n      <td>-0.709981</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1.747204</td>\n      <td>0.672320</td>\n      <td>0.122047</td>\n      <td>6.816164</td>\n      <td>0.882613</td>\n      <td>0.141751</td>\n      <td>391.719036</td>\n      <td>0.034402</td>\n      <td>-0.017196</td>\n      <td>-0.709981</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.413429</td>\n      <td>0.666867</td>\n      <td>0.089861</td>\n      <td>0.000000</td>\n      <td>-0.236134</td>\n      <td>0.007740</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.878246</td>\n      <td>-0.029724</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>10 rows Ã— 57 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(Path('./data/model/immoscout_robust.csv'))\n",
    "\n",
    "df.head(10)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def train_test_split(X, y):\n",
    "    return model_selection.train_test_split(X, y, train_size=0.6, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "def get_random_column_names(columns: list, percentage: float, add_type_columns: bool) -> list:\n",
    "    type_columns = [c for c in columns if c.startswith(\"type_\") and add_type_columns]\n",
    "    regular_columns = [c for c in columns if (not c.startswith(\"type_\")) and random.random() < percentage]\n",
    "    return [*type_columns, *regular_columns]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "def train_linear_regression(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    model = linear_model.LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"LinearRegression\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        \"model\": model\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# Ridge\n",
    "def train_ridge(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    model = linear_model.Ridge()\n",
    "    model.fit(X_train, y_train, 100)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"Ridge\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        \"model\": model\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ensemble"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "def train_random_forest(X_train: pd.DataFrame, X_test: pd.DataFrame, y_train: pd.Series, y_test: pd.Series) -> dict:\n",
    "    model = ensemble.RandomForestRegressor()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    return {\n",
    "        \"type\": \"RandomForest\",\n",
    "        \"columns\": list(X_train.columns),\n",
    "        \"num_columns\": len(X_train.columns),\n",
    "        \"score\": model.score(X_test, y_test),\n",
    "        \"model\": model\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Execution function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of iterations: 1000\n"
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "NUM_ITERATIONS = 500\n",
    "MIN_PERCENTAGE_COLUMNS = 0.2\n",
    "MAX_PERCENTAGE_COLUMNS = 1\n",
    "TRAINING_FUNCTIONS = [train_random_forest]\n",
    "\n",
    "print(\"Total number of iterations:\", NUM_ITERATIONS * len(TRAINING_FUNCTIONS) * 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "X = df.drop(\"price\", axis=1)\n",
    "y = df[\"price\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/00/d026dxr1001fd8rphxcfdzb40000gn/T/ipykernel_67279/1864933156.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mfunc\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mTRAINING_FUNCTIONS\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 9\u001B[0;31m             \u001B[0mresults\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m**\u001B[0m\u001B[0mfunc\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtemp_X_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtemp_X_test\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"add_type_columns\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0madd_type_columns\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     10\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresults\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msort_values\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"score\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mascending\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/var/folders/00/d026dxr1001fd8rphxcfdzb40000gn/T/ipykernel_67279/3028204775.py\u001B[0m in \u001B[0;36mtrain_random_forest\u001B[0;34m(X_train, X_test, y_train, y_test)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mtrain_random_forest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSeries\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m     \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mensemble\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRandomForestRegressor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     return {\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    329\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0missparse\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    330\u001B[0m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"sparse multilabel-indicator for y is not supported.\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 331\u001B[0;31m         X, y = self._validate_data(\n\u001B[0m\u001B[1;32m    332\u001B[0m             \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmulti_output\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"csc\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mDTYPE\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    333\u001B[0m         )\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\u001B[0m in \u001B[0;36m_validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    594\u001B[0m                 \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_array\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"y\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_y_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    595\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 596\u001B[0;31m                 \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcheck_X_y\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mcheck_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    597\u001B[0m             \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    598\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1072\u001B[0m         )\n\u001B[1;32m   1073\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1074\u001B[0;31m     X = check_array(\n\u001B[0m\u001B[1;32m   1075\u001B[0m         \u001B[0mX\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1076\u001B[0m         \u001B[0maccept_sparse\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maccept_sparse\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    897\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    898\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mforce_all_finite\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 899\u001B[0;31m             _assert_all_finite(\n\u001B[0m\u001B[1;32m    900\u001B[0m                 \u001B[0marray\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    901\u001B[0m                 \u001B[0minput_name\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_name\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36m_assert_all_finite\u001B[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001B[0m\n\u001B[1;32m    144\u001B[0m                     \u001B[0;34m\"#estimators-that-handle-nan-values\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m                 )\n\u001B[0;32m--> 146\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmsg_err\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    147\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0;31m# for object dtype data, we only check for NaNs (GH-13254)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for _ in range(NUM_ITERATIONS):\n",
    "    for add_type_columns in [True, False]:\n",
    "        column_percentage = random.random() * (MAX_PERCENTAGE_COLUMNS - MIN_PERCENTAGE_COLUMNS) + MIN_PERCENTAGE_COLUMNS\n",
    "        column_names = get_random_column_names(X_train.columns, column_percentage, add_type_columns)\n",
    "        temp_X_train, temp_X_test = X_train[column_names], X_test[column_names]\n",
    "\n",
    "        for func in TRAINING_FUNCTIONS:\n",
    "            results.append({**func(temp_X_train, temp_X_test, y_train, y_test), \"add_type_columns\": add_type_columns})\n",
    "\n",
    "pd.DataFrame(results).sort_values(\"score\", ascending=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
